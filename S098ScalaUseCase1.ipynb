{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c31ad7d-4299-484c-8e7c-f2e0f42018ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.80.128:4041\n",
       "SparkContext available as 'sc' (version = 3.1.3, master = local[*], app id = local-1647892491148)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "kafkareadDf: org.apache.spark.sql.DataFrame = [key: binary, value: binary ... 5 more fields]\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val kafkareadDf = spark.readStream.format(\"kafka\")\n",
    "                      .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\n",
    "                      .option(\"subscribe\", \"stock-ticks\")\n",
    "                      .option(\"group.id\", \"stock-ticks-group3-na123\")\n",
    "                      .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5080c03f-431a-4dd8-990a-a16c30e77034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kafkareadDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37fb1922-e1e2-4408-8a78-e280716b65b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "stockDf: org.apache.spark.sql.DataFrame = [value: string]\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val stockDf = kafkareadDf.selectExpr(\"CAST(value AS STRING)\")\n",
    "stockDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8668a7b7-b31f-455a-8a63-d7af468ba5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types.{StructField, StructType, DoubleType, StringType, LongType, TimestampType}\n",
       "schema: org.apache.spark.sql.types.StructType = StructType(StructField(symbol,StringType,true), StructField(volume,LongType,true), StructField(price,DoubleType,true), StructField(timestamp,LongType,true))\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import org.apache.spark.sql.types.{StructField, StructType, DoubleType, StringType, LongType, TimestampType}\n",
    "\n",
    "val schema = StructType(\n",
    "    List(\n",
    "  StructField(\"symbol\", StringType, true),\n",
    "    StructField(\"volume\", LongType, true),\n",
    "     StructField(\"price\", DoubleType, true),\n",
    "    StructField(\"timestamp\", LongType, true)  \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0dfc590-f7df-4fb7-b7d9-2be36d06ca49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: struct (nullable = true)\n",
      " |    |-- symbol: string (nullable = true)\n",
      " |    |-- volume: long (nullable = true)\n",
      " |    |-- price: double (nullable = true)\n",
      " |    |-- timestamp: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "jsonStockDf: org.apache.spark.sql.DataFrame = [value: struct<symbol: string, volume: bigint ... 2 more fields>]\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val jsonStockDf = stockDf.withColumn(\"value\", from_json($\"value\",schema))\n",
    "jsonStockDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31b1ca50-e1b0-4b36-a818-83f7143c5fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- symbol: string (nullable = true)\n",
      " |-- volume: long (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "valueDf: org.apache.spark.sql.DataFrame = [symbol: string, volume: bigint ... 2 more fields]\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val valueDf = jsonStockDf.select(\"value.*\")\n",
    "valueDf.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84aad668-5c17-4a02-a5cb-ca7bf523ce8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- symbol: string (nullable = true)\n",
      " |-- volume: long (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- SYMBOL1: string (nullable = true)\n",
      " |-- time: timestamp (nullable = true)\n",
      " |-- YEAR: string (nullable = true)\n",
      " |-- MONTH: string (nullable = true)\n",
      " |-- DAY: string (nullable = true)\n",
      " |-- HOUR: string (nullable = true)\n",
      " |-- MIN: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "timeDf: org.apache.spark.sql.DataFrame = [symbol: string, volume: bigint ... 8 more fields]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Year=2022/Month=03/Day=18/Hour=01/Symbol=TSLA   for every minute, 1 file\n",
    "\n",
    "val timeDf = valueDf.withColumn(\"SYMBOL1\",col(\"symbol\"))\n",
    "                .withColumn(\"timestamp\", col(\"timestamp\")/1000)\n",
    "                .withColumn(\"time\" , to_timestamp(col(\"timestamp\")))\n",
    "                .withColumn(\"YEAR\" ,date_format(col(\"time\"),\"yyyy\"))\n",
    "                .withColumn(\"MONTH\" ,date_format(col(\"time\"),\"MM\"))\n",
    "                .withColumn(\"DAY\" ,date_format(col(\"time\"),\"dd\"))\n",
    "                .withColumn(\"HOUR\" ,date_format(col(\"time\"),\"HH\"))\n",
    "                .withColumn(\"MIN\" ,date_format(col(\"time\"),\"mm\"))\n",
    "                .drop(\"timestamp\")\n",
    "timeDf.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d833c962-b3bd-4ffb-8beb-eace6c247305",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "//echoOnconsole = timeDf.writeStream.outputMode(\"update\").option(\"truncate\", False).format(\"console\").start()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d30af608-9ced-411e-869b-8710a0fac747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.streaming.Trigger\n",
       "res7: org.apache.spark.sql.streaming.StreamingQuery = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@45ebd5f9\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.streaming.Trigger\n",
    "\n",
    "timeDf.writeStream.trigger(Trigger.ProcessingTime(\"60 seconds\"))\n",
    "        .queryName(\"Write ticks to csv2\")\n",
    "        .format(\"csv\")\n",
    "        .option(\"path\", \"hdfs://localhost:9000/scala/layers/raw/csv/\")\n",
    "        .option(\"header\", true)\n",
    "        .option(\"checkpointLocation\", \"file:///tmp/spark43\")\n",
    "        .partitionBy(\"year\", \"month\", \"day\", \"hour\", \"SYMBOL1\")\n",
    "        .option(\"truncate\", false)\n",
    "        .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdf0a3ff-3655-4ccf-a82e-699efeb0f922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql._\n",
       "processBatchData: (candleBatchDf: org.apache.spark.sql.DataFrame, batch_id: Long)Unit\n",
       "res11: org.apache.spark.sql.streaming.StreamingQuery = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@2354e33d\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(process batch called,0,writing ,0)(process batch called,1,writing ,1)(process batch called,2,writing ,1)(process batch called,3,writing ,1)(process batch called,4,writing ,1)(process batch called,5,writing ,1)(process batch called,6,writing ,1)(process batch called,7,writing ,1)(process batch called,8,writing ,1)(process batch called,9,writing ,1)(process batch called,10,writing ,1)(process batch called,11,writing ,1)(process batch called,12,writing ,1)(process batch called,13,writing ,1)(process batch called,14,writing ,1)(process batch called,15,writing ,1)(process batch called,16,writing ,1)(process batch called,17,writing ,1)(process batch called,18,writing ,1)(process batch called,19,writing ,1)(process batch called,20,writing ,1)(process batch called,21,writing ,1)(process batch called,22,writing ,1)(process batch called,23,writing ,1)(process batch called,24,writing ,1)(process batch called,25,writing ,1)(process batch called,26,writing ,1)(process batch called,27,writing ,1)(process batch called,28,writing ,1)(process batch called,29,writing ,1)(process batch called,30,writing ,1)(process batch called,31,writing ,1)(process batch called,32,writing ,1)(process batch called,33,writing ,1)(process batch called,34,writing ,1)(process batch called,35,writing ,1)(process batch called,36,writing ,1)(process batch called,37,writing ,1)(process batch called,38,writing ,1)(process batch called,39,writing ,1)(process batch called,40,writing ,1)(process batch called,41,writing ,1)(process batch called,42,writing ,1)(process batch called,43,writing ,1)(process batch called,44,writing ,1)(process batch called,45,writing ,1)(process batch called,46,writing ,1)(process batch called,47,writing ,1)(process batch called,48,writing ,1)(process batch called,49,writing ,1)(process batch called,50,writing ,1)(process batch called,51,writing ,1)(process batch called,52,writing ,1)(process batch called,53,writing ,1)(process batch called,54,writing ,1)(process batch called,55,writing ,1)(process batch called,56,writing ,1)(process batch called,57,writing ,1)(process batch called,58,writing ,1)(process batch called,59,writing ,1)(process batch called,60,writing ,1)(process batch called,61,writing ,1)(process batch called,62,writing ,1)(process batch called,63,writing ,1)(process batch called,64,writing ,1)(process batch called,65,writing ,1)(process batch called,66,writing ,1)(process batch called,67,writing ,1)(process batch called,68,writing ,1)(process batch called,69,writing ,1)(process batch called,70,writing ,1)(process batch called,71,writing ,1)(process batch called,72,writing ,1)(process batch called,73,writing ,1)(process batch called,74,writing ,1)(process batch called,75,writing ,1)(process batch called,76,writing ,1)(process batch called,77,writing ,1)(process batch called,78,writing ,1)(process batch called,79,writing ,1)(process batch called,80,writing ,1)(process batch called,81,writing ,1)(process batch called,82,writing ,1)(process batch called,83,writing ,1)(process batch called,84,writing ,1)(process batch called,85,writing ,1)(process batch called,86,writing ,1)(process batch called,87,writing ,1)(process batch called,88,writing ,1)(process batch called,89,writing ,1)(process batch called,90,writing ,1)(process batch called,91,writing ,1)(process batch called,92,writing ,1)(process batch called,93,writing ,1)(process batch called,94,writing ,1)(process batch called,95,writing ,1)(process batch called,96,writing ,1)(process batch called,97,writing ,1)(process batch called,98,writing ,1)(process batch called,99,writing ,1)(process batch called,100,writing ,1)(process batch called,101,writing ,1)(process batch called,102,writing ,1)(process batch called,103,writing ,1)(process batch called,104,writing ,1)(process batch called,105,writing ,1)(process batch called,106,writing ,1)(process batch called,107,writing ,1)(process batch called,108,writing ,1)(process batch called,109,writing ,1)(process batch called,110,writing ,1)(process batch called,111,writing ,1)(process batch called,112,writing ,1)(process batch called,113,writing ,1)(process batch called,114,writing ,1)(process batch called,115,writing ,1)(process batch called,116,writing ,1)(process batch called,117,writing ,1)(process batch called,118,writing ,1)(process batch called,119,writing ,1)(process batch called,120,writing ,1)(process batch called,121,writing ,1)(process batch called,122,writing ,1)(process batch called,123,writing ,1)(process batch called,124,writing ,1)(process batch called,125,writing ,1)(process batch called,126,writing ,1)(process batch called,127,writing ,1)(process batch called,128,writing ,1)(process batch called,129,writing ,1)(process batch called,130,writing ,1)(process batch called,131,writing ,1)(process batch called,132,writing ,1)(process batch called,133,writing ,1)(process batch called,134,writing ,1)(process batch called,135,writing ,1)(process batch called,136,writing ,1)(process batch called,137,writing ,1)(process batch called,138,writing ,1)(process batch called,139,writing ,1)(process batch called,140,writing ,1)(process batch called,141,writing ,1)(process batch called,142,writing ,1)(process batch called,143,writing ,1)(process batch called,144,writing ,1)(process batch called,145,writing ,1)(process batch called,146,writing ,1)(process batch called,147,writing ,1)(process batch called,148,writing ,1)(process batch called,149,writing ,1)(process batch called,150,writing ,1)(process batch called,151,writing ,1)(process batch called,152,writing ,1)(process batch called,153,writing ,1)(process batch called,154,writing ,1)(process batch called,155,writing ,1)(process batch called,156,writing ,1)(process batch called,157,writing ,1)(process batch called,158,writing ,1)(process batch called,159,writing ,1)(process batch called,160,writing ,1)(process batch called,161,writing ,1)(process batch called,162,writing ,1)(process batch called,163,writing ,1)(process batch called,164,writing ,1)(process batch called,165,writing ,1)(process batch called,166,writing ,1)(process batch called,167,writing ,1)(process batch called,168,writing ,1)(process batch called,169,writing ,1)(process batch called,170,writing ,1)(process batch called,171,writing ,1)(process batch called,172,writing ,1)(process batch called,173,writing ,1)(process batch called,174,writing ,1)(process batch called,175,writing ,1)(process batch called,176,writing ,1)(process batch called,177,writing ,1)(process batch called,178,writing ,1)(process batch called,179,writing ,1)(process batch called,180,writing ,1)(process batch called,181,writing ,1)(process batch called,182,writing ,1)(process batch called,183,writing ,1)(process batch called,184,writing ,1)(process batch called,185,writing ,1)(process batch called,186,writing ,1)(process batch called,187,writing ,1)(process batch called,188,writing ,1)(process batch called,189,writing ,1)(process batch called,190,writing ,1)(process batch called,191,writing ,1)(process batch called,192,writing ,1)(process batch called,193,writing ,1)(process batch called,194,writing ,1)(process batch called,195,writing ,1)(process batch called,196,writing ,1)(process batch called,197,writing ,1)(process batch called,198,writing ,1)(process batch called,199,writing ,1)(process batch called,200,writing ,1)(process batch called,201,writing ,1)(process batch called,202,writing ,1)(process batch called,203,writing ,1)(process batch called,204,writing ,1)(process batch called,205,writing ,1)(process batch called,206,writing ,1)(process batch called,207,writing ,1)(process batch called,208,writing ,1)(process batch called,209,writing ,1)(process batch called,210,writing ,1)(process batch called,211,writing ,1)(process batch called,212,writing ,1)(process batch called,213,writing ,1)(process batch called,214,writing ,1)(process batch called,215,writing ,1)(process batch called,216,writing ,1)(process batch called,217,writing ,1)(process batch called,218,writing ,1)(process batch called,219,writing ,1)(process batch called,220,writing ,1)(process batch called,221,writing ,1)(process batch called,222,writing ,1)(process batch called,223,writing ,1)(process batch called,224,writing ,1)(process batch called,225,writing ,1)(process batch called,226,writing ,1)(process batch called,227,writing ,1)(process batch called,228,writing ,1)(process batch called,229,writing ,1)(process batch called,230,writing ,1)(process batch called,231,writing ,1)(process batch called,232,writing ,1)(process batch called,233,writing ,1)(process batch called,234,writing ,1)(process batch called,235,writing ,1)(process batch called,236,writing ,1)(process batch called,237,writing ,1)(process batch called,238,writing ,1)(process batch called,239,writing ,1)(process batch called,240,writing ,1)(process batch called,241,writing ,1)(process batch called,242,writing ,1)(process batch called,243,writing ,1)(process batch called,244,writing ,1)(process batch called,245,writing ,1)(process batch called,246,writing ,1)(process batch called,247,writing ,1)(process batch called,248,writing ,1)(process batch called,249,writing ,1)(process batch called,250,writing ,1)(process batch called,251,writing ,1)(process batch called,252,writing ,1)(process batch called,253,writing ,1)(process batch called,254,writing ,1)(process batch called,255,writing ,1)(process batch called,256,writing ,1)(process batch called,257,writing ,1)(process batch called,258,writing ,1)(process batch called,259,writing ,1)(process batch called,260,writing ,1)(process batch called,261,writing ,1)(process batch called,262,writing ,1)(process batch called,263,writing ,1)(process batch called,264,writing ,1)(process batch called,265,writing ,1)(process batch called,266,writing ,1)(process batch called,267,writing ,1)(process batch called,268,writing ,1)(process batch called,269,writing ,1)(process batch called,270,writing ,1)(process batch called,271,writing ,1)(process batch called,272,writing ,1)(process batch called,273,writing ,1)(process batch called,274,writing ,1)(process batch called,275,writing ,1)(process batch called,276,writing ,1)(process batch called,277,writing ,1)(process batch called,278,writing ,1)(process batch called,279,writing ,1)(process batch called,280,writing ,1)(process batch called,281,writing ,1)(process batch called,282,writing ,1)(process batch called,283,writing ,1)(process batch called,284,writing ,1)(process batch called,285,writing ,1)(process batch called,286,writing ,1)(process batch called,287,writing ,1)(process batch called,288,writing ,1)(process batch called,289,writing ,1)(process batch called,290,writing ,1)(process batch called,291,writing ,1)(process batch called,292,writing ,1)(process batch called,293,writing ,1)(process batch called,294,writing ,1)(process batch called,295,writing ,1)(process batch called,296,writing ,1)(process batch called,297,writing ,1)(process batch called,298,writing ,1)(process batch called,299,writing ,1)(process batch called,300,writing ,1)(process batch called,301,writing ,1)(process batch called,302,writing ,1)(process batch called,303,writing ,1)(process batch called,304,writing ,1)(process batch called,305,writing ,1)(process batch called,306,writing ,1)(process batch called,307,writing ,1)(process batch called,308,writing ,1)(process batch called,309,writing ,1)(process batch called,310,writing ,1)(process batch called,311,writing ,1)(process batch called,312,writing ,1)(process batch called,313,writing ,1)(process batch called,314,writing ,1)(process batch called,315,writing ,1)(process batch called,316,writing ,1)(process batch called,317,writing ,1)(process batch called,318,writing ,1)(process batch called,319,writing ,1)(process batch called,320,writing ,1)(process batch called,321,writing ,1)(process batch called,322,writing ,1)(process batch called,323,writing ,1)(process batch called,324,writing ,1)(process batch called,325,writing ,1)(process batch called,326,writing ,1)(process batch called,327,writing ,1)(process batch called,328,writing ,1)(process batch called,329,writing ,1)(process batch called,330,writing ,1)(process batch called,331,writing ,1)(process batch called,332,writing ,1)(process batch called,333,writing ,1)(process batch called,334,writing ,1)(process batch called,335,writing ,1)(process batch called,336,writing ,1)(process batch called,337,writing ,1)(process batch called,338,writing ,1)(process batch called,339,writing ,1)(process batch called,340,writing ,1)(process batch called,341,writing ,1)(process batch called,342,writing ,1)(process batch called,343,writing ,1)"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.sql._\n",
    "def processBatchData(candleBatchDf:DataFrame, batch_id:Long)=\n",
    "{\n",
    "    print (\"process batch called\", batch_id, \"writing \", candleBatchDf.count())\n",
    "    (\n",
    "      candleBatchDf\n",
    "       // .select('*')\n",
    "        .write\n",
    "        .mode(\"append\")\n",
    "        .format(\"csv\")\n",
    "        .partitionBy(\"symbol\",\"YEAR\", \"MONTH\", \"DAY\",\"HOUR\",\"MIN\")\n",
    "        .save(\"hdfs://localhost:9000/Testing71/\")\n",
    "      )\n",
    "}  \n",
    "\n",
    "\n",
    "timeDf.writeStream.outputMode(\"append\")\n",
    "         .option(\"checkpointLocation\", \"file:///tmp/spark371\")\n",
    "         .foreachBatch(processBatchData _).start()\n",
    "        \n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba64c560-3f1b-4c92-b30b-76197d5333f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
