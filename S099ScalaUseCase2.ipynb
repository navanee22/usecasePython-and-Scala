{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8d57748-8ec5-40c6-80af-ae069b64fce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#     kafka-topics  --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic stock-ticks \n",
    "#     kafka-console-consumer --bootstrap-server localhost:9092 --topic  stock-ticks   --from-beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6761e12-bb0a-4a83-89a6-5a9d35eea7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "readfromkafkaDf: org.apache.spark.sql.DataFrame = [key: binary, value: binary ... 5 more fields]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val readfromkafkaDf= spark.readStream.format(\"kafka\").option(\"kafka.bootstrap.servers\", \"localhost:9092\").option(\"subscribe\", \"stock-ticks\").option(\"group-id\",\"stock-ticks-group4-nav1\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f7924ba-9025-4bac-9396-32fcef7be41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "readfromkafkaDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ff150b9-1d7b-4b6b-a767-0c5f28c1de0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "stockDf: org.apache.spark.sql.DataFrame = [value: string, timestamp: timestamp]\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val stockDf= readfromkafkaDf.selectExpr((\"CAST(value as STRING)\"),(\"timestamp\"))\n",
    "stockDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8668a7b7-b31f-455a-8a63-d7af468ba5ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types.{StructField, StructType, DoubleType, StringType, LongType, TimestampType}\n",
       "schema: org.apache.spark.sql.types.StructType = StructType(StructField(symbol,StringType,true), StructField(volume,LongType,true), StructField(price,DoubleType,true), StructField(timestamp,LongType,true))\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import org.apache.spark.sql.types.{StructField, StructType, DoubleType, StringType, LongType, TimestampType}\n",
    "\n",
    "val schema = StructType(\n",
    "    List(\n",
    "  StructField(\"symbol\", StringType, true),\n",
    "    StructField(\"volume\", LongType, true),\n",
    "     StructField(\"price\", DoubleType, true),\n",
    "    StructField(\"timestamp\", LongType, true)  \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16ad09ca-f19e-4eb7-bd42-df459883fecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: struct (nullable = true)\n",
      " |    |-- symbol: string (nullable = true)\n",
      " |    |-- volume: long (nullable = true)\n",
      " |    |-- price: double (nullable = true)\n",
      " |    |-- timestamp: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "stringToJsonStockDf: org.apache.spark.sql.DataFrame = [value: struct<symbol: string, volume: bigint ... 2 more fields>, timestamp: timestamp]\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val stringToJsonStockDf= stockDf.withColumn(\"value\", from_json($\"value\",schema))\n",
    "stringToJsonStockDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a68e488-9f89-4c2d-b646-51214651efea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- symbol: string (nullable = true)\n",
      " |-- volume: long (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- timestamp: long (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "valueDf: org.apache.spark.sql.DataFrame = [symbol: string, volume: bigint ... 2 more fields]\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val valueDf= stringToJsonStockDf.select(\"value.*\")\n",
    "valueDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9deeff4-2ed2-4844-8d74-550d73242736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- symbol: string (nullable = true)\n",
      " |-- volume: long (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- time: timestamp (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "timeDf: org.apache.spark.sql.DataFrame = [symbol: string, volume: bigint ... 2 more fields]\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "val timeDf= valueDf .withColumn(\"timestamp\", col(\"timestamp\")/1000)\n",
    "                .withColumn(\"time\" , to_timestamp(col(\"timestamp\")))\n",
    "                .drop(\"timestamp\")\n",
    "timeDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb38e00c-6770-4dd3-b08d-eb2fccc8f7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- symbol: string (nullable = true)\n",
      " |-- window: struct (nullable = false)\n",
      " |    |-- start: timestamp (nullable = true)\n",
      " |    |-- end: timestamp (nullable = true)\n",
      " |-- volume: long (nullable = true)\n",
      " |-- high: double (nullable = true)\n",
      " |-- low: double (nullable = true)\n",
      " |-- first: double (nullable = true)\n",
      " |-- last: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions._\n",
       "stock1minDf: org.apache.spark.sql.DataFrame = [symbol: string, window: struct<start: timestamp, end: timestamp> ... 5 more fields]\n"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "val stock1minDf= timeDf.groupBy($\"symbol\", window($\"time\", \"60 Seconds\"))\n",
    "                                .agg(sum(\"volume\").alias(\"volume\"),\n",
    "                                max(\"price\").alias(\"high\"),\n",
    "                                min(\"price\").alias(\"low\"),\n",
    "                                first(\"price\").alias(\"first\"),\n",
    "                                last(\"price\").alias(\"last\")\n",
    "                                    )\n",
    "stock1minDf.printSchema() \n",
    "\n",
    "\n",
    "//    import org.apache.spark.sql.functions._\n",
    "//    df.groupBy(\"department\").agg(max(\"age\"), sum(\"expense\"))\n",
    "\n",
    " // echoOnconsole = stock1minDf\n",
    " //                 .writeStream\n",
    " //                 .outputMode(\"update\")\n",
    " //                 .format(\"console\")\n",
    " //                 .option(\"truncate\", false)\n",
    " //                 .start()\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cf97cc-03e1-470c-bc57-aa7cad2f1a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock3minDf= timeDf.groupBy(\"symbol\", F.window(\"time\", \"3 minutes\"))\\\n",
    "                                .agg( F.sum(\"volume\").alias(\"volume\"),\\\n",
    "                                 F.max(\"price\").alias(\"high\"),\\\n",
    "                                F.min(\"price\").alias(\"low\"),\\\n",
    "                                F.first(\"price\").alias(\"first\"),\\\n",
    "                                F.last(\"price\").alias(\"last\")\n",
    "                                    )\n",
    "stock3minDf.printSchema()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f48eea-691b-4312-95b8-1e2a3aaffacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock5minDf= timeDf.groupBy(\"symbol\", F.window(\"time\", \"5 minutes\"))\\\n",
    "                                .agg( F.sum(\"volume\").alias(\"volume\"),\\\n",
    "                                 F.max(\"price\").alias(\"high\"),\\\n",
    "                                F.min(\"price\").alias(\"low\"),\\\n",
    "                                F.first(\"price\").alias(\"first\"),\\\n",
    "                                F.last(\"price\").alias(\"last\")\n",
    "                                    )\n",
    "\n",
    "stock5minDf.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b003c36c-3feb-44ca-8a02-96d87bfc519e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "stock1minDfTojsonDf: org.apache.spark.sql.DataFrame = [value: string]\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val stock1minDfTojsonDf= stock1minDf.drop(\"window\").selectExpr(\"to_json(struct(*)) AS value\")\n",
    "stock1minDfTojsonDf.printSchema()\n",
    "\n",
    "// stock3minDfTojsonDf= stock3minDf.drop(\"window\").selectExpr(\"to_json(struct(*)) AS value\")\n",
    "// stock3minDfTojsonDf.printSchema()\n",
    "\n",
    "// stock5minDfTojsonDf= stock5minDf.drop(\"window\").selectExpr(\"to_json(struct(*)) AS value\")\n",
    "// stock5minDfTojsonDf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "336d7e0b-ed0c-4ece-b074-1d5edd127ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res19: org.apache.spark.sql.streaming.StreamingQuery = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@567170d6\n"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock1minDfTojsonDf.writeStream\n",
    "             .format(\"kafka\")\n",
    "            .outputMode(\"update\")\n",
    "             .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\n",
    "            .option(\"topic\", \"scala-stock-ticks-1min\")\n",
    "            .option(\"checkpointLocation\", \"file:///tmp/spark6\")\n",
    "            .start()\n",
    "\n",
    "\n",
    "// stock3minDfTojsonDf.writeStream\\\n",
    "//              .format(\"kafka\")\\\n",
    "//             .outputMode(\"update\")\\\n",
    "//              .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\\\n",
    "//             .option(\"topic\", \"stock-ticks-3min\")\\\n",
    "//             .option(\"checkpointLocation\", \"file:///tmp/spark7\")\\\n",
    "//             .start()\n",
    "\n",
    "// stock5minDfTojsonDf.writeStream\\\n",
    "//              .format(\"kafka\")\\\n",
    "//             .outputMode(\"update\")\\\n",
    "//              .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\\\n",
    "//             .option(\"topic\", \"stock-ticks-5min\")\\\n",
    "//             .option(\"checkpointLocation\", \"file:///tmp/spark8\")\\\n",
    "//             .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a6b34b-c1d6-4db7-b178-bb3cd5ae456c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
